{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matthew Peetz\n",
    "# Regis University\n",
    "# MSDS 621\n",
    "# Week 4 Lab: SQL vs NoSQL Databases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"right\" style=\"padding-left:10px;\" src=\"figures_wk4/movies.png\" width = 200>\n",
    "\n",
    "This week you will be building and querying both a SQL and NoSQL database. The dataset that we will be using is the MovieLens 1 million ratings dataset. \n",
    "\n",
    "The MovieLens dataset is comprised of 3 files:<br>\n",
    "    * Users\n",
    "    * Movies\n",
    "    * Reviews\n",
    "\n",
    "One complete review consists of data from all three tables joined together. We will work through that part together. All 3 files and a dataset descriptive document are located in the assign_wk4 folder.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At a high level, this assignment will follow our lecture material's progression:\n",
    "\n",
    "* Load MovieLens tables into SQLite (good time to find that \"multiple insert\" I hinted about...)\n",
    "* Create a query to retrieve reviews into a cursor\n",
    "* Create a dataclass that represents a movie review\n",
    "* Translate rows of the cursor into a list of MovieReview objects\n",
    "* Translate the list of MovieReviews into a list of dictionaries\n",
    "* Load the list of dictionaries into TinyDB (using `insert_multiple()`)\n",
    "\n",
    "To help you out, I have written most of the code for you. You need to go through and replace all the `********` strings with the appropriate code.  Also, there are questions imbedded in the code.  So keep an eye out for those. You need to thoroughly answer all of these.\n",
    "\n",
    "Oh! Feel free to add additional markdown text as you go to capture your thoughts/analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deliverables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload your Jupyter Notebook.\n",
    "\n",
    "**Note::** Make sure you have clearly indicated the answers to each question within your notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 - Storing in SQLite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, you are expected to read MovieLens's README file to find information to proceed. \n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Hint::</b> Jupyter notebook and JupyterLabs can open it.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Questions::</b> <br>\n",
    "1) What columns link the 3 files together to form a single review? <br>\n",
    "2) What seperator(s) are used in these files?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) User ID is the unique key for the uses file. Movie ID is the unique key for the movies file. They are linked in the review file which has both of these foreign keys."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) A double colon \"::\" is used to seperate the data in these files, follow by a line return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in between the quotes for your own system\n",
    "sql_db_path = \"\\\\Users\\matth\\MSDS_621_Data_Wrangling\\Week4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in the connection string between the parentheses\n",
    "db = dataset.connect('sqlite:///databases/movie_review.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are these files comma-separated? (Question #2 above)\n",
    "separator = '::'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get column names from the README\n",
    "# Replace *'s with column names\n",
    "users_head = \"UserID::Gender::Age::Occupation::Zip_code\".split(separator)\n",
    "movies_head = \"MovieID::Title::Genres\".split(separator)\n",
    "ratings_head = \"UserID::MovieID::Rating::Timestamp\".split(separator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Questions::</b> <br>\n",
    "3) Before executing the next line, stop and think what should be output. Describe in detail what yo are expecting\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) I would expect to get the column header, without any \"::\" turned into a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(users_head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['UserID', 'Gender', 'Age', 'Occupation', 'Zip_code']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Questions::</b> <br>\n",
    "4) Does the actual output match your expectation? If not, explain why?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Yes, it does, I used the \"type\" command to make sure that I did have a list as well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it is time to create the database tables. As mentioned, there will be three of them. Interestingly, the `USERS` table and the `MOVIES` table both have unique ID fields alread - we will have to take that into account. The `RATINGS` table, on the other hand, does not have a unique ID column, so we don't have to worry about it. \n",
    "\n",
    "The general, simple format to create a table is:\n",
    "\n",
    "`table_variable = db.create_table(\"table_name\")` . # This is what you use for ratings.\n",
    "\n",
    "But, in the case where the data already has an ID, we have to tell DataSet about it. The general form is:\n",
    "\n",
    "`table_variable = db.create_table(\"table_name\", primary_id=\"ID_column_name\", primary_type=db.types.integer)`\n",
    "\n",
    "So, in the case of the `MOVIES` table, the `MovieID` column is the primary key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    ratings_table = db.create_table(\"ratings\")\n",
    "except:\n",
    "    print(\"that did not work\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    users_table = db.create_table(\n",
    "        \"users\", primary_id=\"User_ID\", primary_type=db.types.integer\n",
    "    )\n",
    "except:\n",
    "    print(\"that did not work\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    movies_table = db.create_table(\n",
    "        \"movies\", primary_id=\"Movie_ID\", primary_type=db.types.integer\n",
    "    )\n",
    "except:\n",
    "    print(\"that did not work\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can, and probably should, put those `create_table()` function calls in `try / except` blocks.\n",
    "\n",
    "Let's set up variables for the data file names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_file = \"assign_wk4/users.dat\"\n",
    "movies_file = \"assign_wk4/movies.dat\"\n",
    "ratings_file = \"assign_wk4/ratings.dat\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Questions::</b> <br>\n",
    "Having the ID column in the data caused one difference in our table creation (in comparison to how we did this in Week 2). <br> And yes, you might have to go back and review that!) <br><br>\n",
    "5) Do you notice any other differences, and if so, what are they? <br>\n",
    "6) If there is a difference, why is it different?<br>\n",
    "7) If there is a difference, how does it affect the data retrieved with a SELECT statement?  \n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) One other difference is the primary keys in the user and movies files, which allow the review file to by connected to them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. The primary keys make sure that there is a unique value in each of the rows, ie. if there are multiple John Smiths they would each still have a key. It also makes the table joinable with the review files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. The SELECT statement can now select date from multiple tables to JOIN together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK. Here it is, the moment you've all been waiting for -- we can start stuffing data in the tables we created. \n",
    "\n",
    "There is one more thing to show you about the insert. You might remember that this data set is called **\"ml-1m\"** which stands for _MovieLens - 1 million rows_. In the grand scheme of modern data storage, 1 million rows isn't a huge number, but it **is** enough to make even a fast laptop like mine choke a bit, so we are going to use a technique that many RDBMS systems call **Bulk Insert.** \n",
    "\n",
    "Bulk insert is optimized for inserting large amounts of similarly-structured data. SQLite is relatively fast so let's do a quick comparison, using the user's table. After that, it will be **up to you to populate the other 2 tables.** We will also use that progress bar from the FTE, just for fun."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1.47 s\n",
      "Wall time: 5.18 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with open (users_file) as ufile:\n",
    "    for line in ufile:\n",
    "        u_dict = dict(zip(users_head, line.split(\"::\")))\n",
    "        users_table.insert(u_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the table before trying to insert again\n",
    "# You might remember how to do this from Week 2.\n",
    "\n",
    "if (len(db.tables) > 0):\n",
    "    for table in db.tables:\n",
    "        db[table].drop()\n",
    "\n",
    "# HINT: you need the table name, and the drop command..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 64.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "users_list = []\n",
    "with open(users_file) as ufile:\n",
    "    for line in ufile:\n",
    "        users_list.append(dict(zip(users_head, line.split(\"::\"))))\n",
    "users_table.insert_many(users_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "Now **YOU** can decide how you want to do the other two tables, using `insert()` or `insert_many()`.\n",
    "\n",
    "Since there are only 2 of them, I will let you do them one by one. _Don't get used to it!_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to insert or insert_many movies_file here\n",
    "movies_list = []\n",
    "with open(movies_file) as ufile:\n",
    "    for line in ufile:\n",
    "        movies_list.append(dict(zip(movies_head, line.split(\"::\"))))\n",
    "movies_table.insert_many(movies_list)\n",
    "# I had an odd error in this file, the line below gets around it\n",
    "# with open(movies_file, errors=\"ignore\") as mfile:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to insert or insert_many ratings_file here\n",
    "ratings_list = []\n",
    "with open(ratings_file) as ufile:\n",
    "    for line in ufile:\n",
    "        ratings_list.append(dict(zip(ratings_head, line.split(\"::\"))))\n",
    "ratings_table.insert_many(ratings_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<strong>Success!</strong> At this point you should have a working relational database containing the MovieLens data!. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to check that there is data in all your tables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000209"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ratings_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3883"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(movies_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6040"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(users_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQL Joins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Records are divided into multiple tables due to the process of **data normalization**. We have to **join tables** in our `SELECT` queries to get one full \n",
    "movie rating. \n",
    "\n",
    "In general, the **left join** or **left inner join** is the most common, although there are several types. The *left* part refers to the actual layout if you were putting the printed tables side by side on your desk. A left join/left inner join means you have a table with foreign keys on the left side and you are trying to match those keys to their primary keys on the right. Let's look at an example:\n",
    "\n",
    "<center>Movie</center>\n",
    "\n",
    "| MovieID | Title | Genre |\n",
    "|---------|-------|-------|\n",
    "|1 | Toy Story (1995)  | Animation|Children's|Comedy |\n",
    "|2 | Jumanji (1995) | Adventure|Children's|Fantasy |\n",
    "|3 | Grumpier Old Men (1995) | Comedy|Romance |\n",
    "|4 | Waiting to Exhale (1995) | Comedy|Drama |\n",
    "|5 | Father of the Bride Part II (1995) | Comedy |\n",
    "\n",
    "<center>Users</center>\n",
    "\n",
    "| UserID | Gender | Age | Occupation | ZipCode |\n",
    "|--------|--------|-----|------------|---------|\n",
    "| 1 | F | 1 | 10 | 48067 |\n",
    "| 2 | M | 56 | 16 | 70072 |\n",
    "| 3 | M | 25 | 15 | 55117 |\n",
    "| 4 | M | 45 | 7 | 02460 |\n",
    "| 5 | M | 25 | 20 | 55455 |\n",
    "\n",
    "\n",
    "<center>Ratings</center>\n",
    "\n",
    "| UserID | MovieID | Rating | Timestamp|\n",
    "|--------|---------|--------|----------|\n",
    "| 1 | 1193 | 5 | 978300760|\n",
    "| 1 | 661: | 3 | 978302109|\n",
    "| 1 | 914: | 3 | 978301968|\n",
    "| 1 | 3408 | 4 | 978300275|\n",
    "| 1 | 2355 | 5 | 978824291|\n",
    "\n",
    "It should be obvious in this small example that Ratings are linked to both Movie and Users through their ids. So, to get a complete rating record, we need the Movie record where the MovieIDs match and the user where the UserIDs match. In SQL that loobks like this: \n",
    "\n",
    "SQL keywords are in caps.\n",
    "\n",
    "```\n",
    "SELECT m.title, m.genres, u.Gender, u.Age, u.Occupation, u.ZipCode, r.Rating, r.Timestamp \n",
    "FROM movies m \n",
    "INNER JOIN ratings r ON m.MovieID = r.MovieID \n",
    "INNER JOIN users u ON r.UserID = u.UserID \n",
    "ORDER BY m.Title ASC;\n",
    "```\n",
    "\n",
    "Normally, when referencing columns from multiple tables, you have to prefix the column name with the table name, but in this case I used a shortcut -- in the FROM part, I gave each table a one-letter alias. \n",
    "\n",
    "Also notice the last two lines. These will put all the matching movie titles together and then alphabetize the list. \n",
    "\n",
    "Let's try it and see what comes out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put the query in here. NOTE: If you break up the lines, you need \n",
    "# a \"continuation character\" at the end of the line. \n",
    "\n",
    "movie_query = \"SELECT m.title, m.genres, u.Gender, u.Age, u.Occupation, u.Zip_code, r.Rating, r.Timestamp \\\n",
    "    FROM movies m \\\n",
    "    INNER JOIN ratings r ON m.MovieID = r.MovieID \\\n",
    "    INNER JOIN users u ON r.UserID = u.UserID \\\n",
    "    ORDER BY m.Title ASC;\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the command to execute a query. \n",
    "# Reference: https://dataset.readthedocs.io/en/latest/api.html#dataset.Database.query\n",
    "query_result = db.query(movie_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<dataset.util.ResultIter object at 0x0000019F679FB940>\n"
     ]
    }
   ],
   "source": [
    "print(query_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('Title', '$1,000,000 Duck (1971)'),\n",
       "             ('Genres', \"Children's|Comedy\\n\"),\n",
       "             ('Gender', 'F'),\n",
       "             ('Age', '35'),\n",
       "             ('Occupation', '1'),\n",
       "             ('Zip_code', '82601\\n'),\n",
       "             ('Rating', '3'),\n",
       "             ('Timestamp', '975093319\\n')])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert that result into a list for ease of use.\n",
    "movie_list = []\n",
    "for movie in query_result:\n",
    "    movie_list.append(movie)\n",
    "\n",
    "# Print out first movie to see what is stored in the list\n",
    "movie_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - Storing in TinyDB\n",
    "\n",
    "Hopefully you remember that TinyDB inserts dictionaries as documents. This means that the data in the `movie_list` variable is in the correct form to insert. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tinydb import TinyDB, Query, where\n",
    "\n",
    "tiny_db = TinyDB(\"ml_nosql.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiny_db.insert_multiple(movie_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "  <strong>Success!</strong> At this point you should have a working NoSQL database containing the MovieLens data!.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can actually start using this data. \n",
    "\n",
    "SQL has some aggregation functions that can be interesting. For example, to find an average of a numeric column:\n",
    "\n",
    "`select avg(column) from table where condition;`\n",
    "\n",
    "<div class=\"alert alert-danger\">\n",
    "  <strong>Note:</strong> At this point, I'm not sure that the Dataset library gains us anything, since we are just passing straight SQL through it. You can continue to use Dataset or switch to the SQLite3 library. I'll stay with Dataset, since it is already loaded. \n",
    "</div>\n",
    "\n",
    "We can modify our join from above to get an average rating from women for the movie \"Die Hard\" like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_query = \"select m.title, u.Gender, avg(r.Rating)\\\n",
    "from movies m \\\n",
    "inner join ratings r on m.MovieID = r.MovieID \\\n",
    "inner join users u on r.UserID = u.UserID \\\n",
    "where u.Gender = 'F' and m.title = 'Die Hard (1988)';\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_result = db.query(movie_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[OrderedDict([('Title', 'Die Hard (1988)'),\n",
       "              ('Gender', 'F'),\n",
       "              ('avg(r.Rating)', 3.9185667752442996)])]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A quick little list comprehension to extract the results\n",
    "f_avg = [row for row in query_result]\n",
    "\n",
    "f_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average female rating for Die Hard (1988) is 3.9185667752442996\n"
     ]
    }
   ],
   "source": [
    "# So, to print it nicely:\n",
    "print(f\"Average female rating for {f_avg[0]['Title']} is {f_avg[0]['avg(r.Rating)']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That process is slightly more manual in TinyDB. Here, we can use TinyDB's `where()` command along with `matches()` to find movies with the right title, then use a logical and `&` to limit it to women. We can also take advantage of Python's built in `sum()` and `len()` commands to help us out.\n",
    "\n",
    "It sounds more complicated than it is. Like this:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "female_dh_set = tiny_db.search( (where('Title').matches('Die Hard')) & (where('Gender').matches('F')) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That gives us a list of dictionaries, prove that is true to yourself, if you need to.\n",
    "\n",
    "The rest is simple (Remember all numbers are stored as strings!):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "dh_avg_f = sum(int(r['Rating']) for r in female_dh_set) / len(female_dh_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average: 3.7107438016528924\n"
     ]
    }
   ],
   "source": [
    "print(f'Average: {dh_avg_f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Questions::</b> <br>\n",
    "8) What is the age range of female reviewers of \"Gone With The Wind?\" (Hint: in SQL, you can use a column more than once.)(Hint2: There may be built in functions that help.) <br>\n",
    "9) Using the relational database you built, compare M and F average ratings for \"Die Hard.\" <br>\n",
    "10) Do the same comparison, as in question 9, with the NoSQL database. <br>\n",
    "11) Do the averages match? If they don't, please provide a detailed explanation as to why not. You will need to write additional queries to back-up and defend your analysis.(Hint: They don't match!)\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. What is the age range of female reviewers of \"Gone With The Wind\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum Age: 1\n",
      "Maximum Age: 56\n"
     ]
    }
   ],
   "source": [
    "female_gwtw_set = tiny_db.search( (where('Title').matches('Gone with the Wind')) & (where('Gender').matches('F')) )\n",
    "\n",
    "gwtw_min_age = min(int(r['Age']) for r in female_gwtw_set)\n",
    "gwtw_max_age = max(int(r['Age']) for r in female_gwtw_set)\n",
    "\n",
    "print(f'Minimum Age: {gwtw_min_age}')\n",
    "print(f'Maximum Age: {gwtw_max_age}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_query = \"select m.title, u.Gender, r.Rating, min(u.Age)\\\n",
    "from movies m \\\n",
    "inner join ratings r on m.MovieID = r.MovieID \\\n",
    "inner join users u on r.UserID = u.UserID \\\n",
    "where u.Gender = 'F' and m.title = 'Gone with the Wind (1939)';\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_result = db.query(movie_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[OrderedDict([('Title', 'Gone with the Wind (1939)'),\n",
       "              ('Gender', 'F'),\n",
       "              ('Rating', '5'),\n",
       "              ('min(u.Age)', '1')])]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A quick little list comprehension to extract the results\n",
    "gwtw_min = [row for row in query_result]\n",
    "\n",
    "gwtw_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_query = \"select m.title, u.Gender, r.Rating, max(u.Age)\\\n",
    "from movies m \\\n",
    "inner join ratings r on m.MovieID = r.MovieID \\\n",
    "inner join users u on r.UserID = u.UserID \\\n",
    "where u.Gender = 'F' and m.title = 'Gone with the Wind (1939)';\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_result = db.query(movie_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[OrderedDict([('Title', 'Gone with the Wind (1939)'),\n",
       "              ('Gender', 'F'),\n",
       "              ('Rating', '5'),\n",
       "              ('max(u.Age)', '56')])]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A quick little list comprehension to extract the results\n",
    "gwtw_max = [row for row in query_result]\n",
    "\n",
    "gwtw_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Youngest Age for viewers of Gone With The wind is {'1'}\n",
      "The Youngest Age for viewers of Gone With The wind is {'56'}\n"
     ]
    }
   ],
   "source": [
    "# So, to print it nicely:\n",
    "print(\"The Youngest Age for viewers of Gone With The wind is\", {gwtw_min[0]['min(u.Age)']})\n",
    "print(\"The Youngest Age for viewers of Gone With The wind is\", {gwtw_max[0]['max(u.Age)']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately is would appear that someone set up an account and listed their age as 1, which means that that is the minimum age that someone watched Gone With the Wind at "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9) Using the relational database you built, compare M and F average ratings for \"Die Hard.\" <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_query = \"select m.title, u.Gender, avg(r.Rating)\\\n",
    "from movies m \\\n",
    "inner join ratings r on m.MovieID = r.MovieID \\\n",
    "inner join users u on r.UserID = u.UserID \\\n",
    "where u.Gender = 'M' and m.title = 'Die Hard (1988)';\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_result = db.query(movie_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[OrderedDict([('Title', 'Die Hard (1988)'),\n",
       "              ('Gender', 'M'),\n",
       "              ('avg(r.Rating)', 4.1677704194260485)])]"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A quick little list comprehension to extract the results\n",
    "m_avg = [row for row in query_result]\n",
    "\n",
    "m_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The female average rating for Die Hard was 3.92, the mail average was 4.17."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10) Do the same comparison, as in question 9, with the NoSQL database. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average for Females: 3.7107438016528924\n",
      "Average for Males: 3.833167825223436\n"
     ]
    }
   ],
   "source": [
    "male_dh_set = tiny_db.search( (where('Title').matches('Die Hard')) & (where('Gender').matches('M')) )\n",
    "\n",
    "dh_avg_m = sum(int(r['Rating']) for r in male_dh_set) / len(male_dh_set)\n",
    "\n",
    "print(f'Average for Females: {dh_avg_f}')\n",
    "\n",
    "print(f'Average for Males: {dh_avg_m}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The female average using the SQL database is 3.92, while the male average is 4.17. If the same comparison is done using the NoSQL database the female average is 3.71 and the male average is 3.83. Why is this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3021\n"
     ]
    }
   ],
   "source": [
    "# Looking at the length of the male_dh_set NoSQL\n",
    "print(len(male_dh_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at the length of the male info in the SQL set\n",
    "movie_query = \"select m.title, u.Gender, COUNT(r.Rating)\\\n",
    "from movies m \\\n",
    "inner join ratings r on m.MovieID = r.MovieID \\\n",
    "inner join users u on r.UserID = u.UserID \\\n",
    "where u.Gender = 'M' and m.title = 'Die Hard (1988)';\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_result = db.query(movie_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[OrderedDict([('Title', 'Die Hard (1988)'),\n",
       "              ('Gender', 'M'),\n",
       "              ('COUNT(r.Rating)', 1359)])]"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A quick little list comprehension to extract the results\n",
    "m_count = [row for row in query_result]\n",
    "\n",
    "m_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The count for the NoSQL set is 3,021. Meaning that there are 3,021 reviews of Die Hard that meet the criteria. The SQL set is only 1,359, or about half the size. This means that the two commands are somehow pulling a different set of data out of the data base. Why is this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average for Females: 3.7107438016528924\n",
      "Average for Males: 3.832230311052283\n"
     ]
    }
   ],
   "source": [
    "male_dh_set = tiny_db.search( (where('Title').matches('Die')) & (where('Gender').matches('M')) )\n",
    "\n",
    "dh_avg_m = sum(int(r['Rating']) for r in male_dh_set) / len(male_dh_set)\n",
    "\n",
    "print(f'Average for Females: {dh_avg_f}')\n",
    "\n",
    "print(f'Average for Males: {dh_avg_m}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(male_dh_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTE: I cleared the output of the above command as it created a 143 page notebook. It has a listed where you could see that all the die hard movies were being pulled, and not just the original christmas classic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you rerun the search you can use the word \"Die\" and see what the problem is. The term it not specific and it is pulling all the movies that have \"Die\" in the title. This includes Die Hard, Die Hard with a Vengance, Dir Harder, etc. All great movies but not the one that we were searching for."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "In previous cources at Regis I have used the cmd terminal to create SQL databases, I have also played around (a little) with MSSql. Both of them require a great deal of patience as you punch commands into the terminal and wait for a response. Using TinyDB, python, and a jupyter notebook made storing and accessing data in a database much more stream lined and easier.\n",
    "\n",
    "I also learned that you have to be really careful with your query commands. I would have never though twice about either of the numbers reported for the Die Hard ratings if I had been using just one of the programs. It was a good demonstration on how to utlize query commands, analyze the data that is returned, and double check it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
